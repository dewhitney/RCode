## David Whitney's Homework 4
## Biostatistics 562

### Problem 1
For a differential expression simulation study, say 1000 genes are measured on 100 individuals. Let the first 50 individuals constitute *class1* and the second 50 individuals be *class2*. Suppose that expression levels are independent and normally distributed across genes. For individuals in *class2*, let the last 100 genes be distributed N(0.5,1). For all other genes, assume that the distribution of gene expression is standard normal.

```{r, echo=FALSE}
set.seed(1990)

person = function(genes=1000,de=100,mean){
  c(rnorm(genes-de),mean+rnorm(de))
  }
```

### 1a.
Run one simulation of the experiment and test for differentially expressed genes (genes with mean differences between the two classes) with a false discovery rate cutoff of 10%. How many genes were called significant? How many of these were false discoveries?

```{r, cache=TRUE, echo=FALSE}
experiment = function(N,mean1=0,mean2,genes=1000,de=100){
  class1 = replicate(N, person(mean=mean1))
  class2 = replicate(N, person(mean=mean2))
  return(cbind(class1,class2))
  }

N = 50
XP = experiment(N=N,mean2=0.5)

class = 1:N
p.values = apply(XP,MARGIN=1,FUN=function(X){t.test(X[class],X[-class])$p.val})
adjust.vals = p.adjust(p.values,method="BH")

fdr = 0.10
n.discoveries = sum(adjust.vals < fdr)
n.false = sum(adjust.vals[1:900] < fdr)
```

We find 37 genes that have a significant mean expression between the two classes and 2 of these were false discoveries, having been observed in the first 900 genes.

### 1b.
Repeat this experiment 1000 times. Of the 100 genes we are searching for, what proportion do we find on average (this is known as the true discovery rate TDR)? Of the genes we call significant what proportion on average are false discoveries?  Relate these ideas to the statistical power of our experiment!

```{r, echo=FALSE, cache=TRUE }
do.one = function(N=50,meandiff=0.5,fdr=0.10){
  XP = experiment(N=N,mean2=meandiff)
  class = 1:N
  p.values = apply(XP,MARGIN=1,FUN=function(X){t.test(X[class],X[-class])$p.val})
  BH.vals = p.adjust(p.values,method="BH")
  bon.vals = p.adjust(p.values,method="bonferroni")

  BH.n.discoveries = sum(BH.vals < fdr)
  BH.n.true = sum(BH.vals[901:1000] < fdr)
  BH.n.false = sum(BH.vals[1:900] < fdr)
  BH.fdp = BH.n.false/BH.n.discoveries
  if(BH.n.discoveries==0){BH.fdp=0}
  BH.tdr = BH.n.true/100

  bon.n.discoveries = sum(bon.vals < fdr)
  bon.n.true = sum(bon.vals[901:1000] < fdr)
  bon.n.false = sum(bon.vals[1:900] < fdr)
  bon.fdp = bon.n.false/bon.n.discoveries
  if(bon.n.discoveries==0){bon.fdp=0}
  bon.tdr = bon.n.true/100  
  
  return(c(BH_FDP=BH.fdp,BH_TDR=BH.tdr,Bonf_FDP=bon.fdp,Bonf_TDR=bon.tdr))
}

set.seed(1776)
B = 1000

TrueFalse.1 = apply(replicate(B, do.one()), MARGIN=1, FUN=mean)
```

After running 1000 of the above simulation studies, we found that the proportion of discoveries that were false discoveries was 0.0905 and the proportion of true discoveries was 0.3189. Power is the probability of rejecting when there is a true effect, so the true discovery rate we estimate is an estimate of the power.

### 1c.
Why might this lead to concern about the reproducibility in these microarray experiments?</br></br>

If the power of microarray studies is only 0.3189 and the FDR is being controlled at near .0905, then we are unlikely to detect true effects and we will further expect that of the effects that we are detecting, nearly 10% of them will be false discoveries.

### Problem 2
We now explore the scenarios under which using FDR as opposed to FWE gives significant additional power.

### 2a.
We consider the study design from _Problem 1_ but assume now that the mean expression for the last 100 genes of _class2_ follow a N(2,1) distribution. 

```{r, echo=FALSE, cache=TRUE}
set.seed(4951)
TrueFalse.2a = apply(replicate(B, do.one(meandiff=2)), MARGIN=1, FUN=mean)
```

When we control the FDR at 10%, we observe a false discovery proportion of 0.0895 and 100% TDR. When we control FWE at .1, we observe a false discovery proportion of 0.0007 and 100% TDR. In this case, the Bonferroni correction outperforms Benjamini-Hochberg by having equal power and a lower Type I error rate.

### 2b.
We consider the study design from _Problem 1_ but assume now that the mean expression for the last 100 genes of _class2_ follow a N(0.2,1) distribution. 

```{r, echo=FALSE, cache=TRUE}
set.seed(7756)
TrueFalse.2b = apply(replicate(B, do.one(meandiff=.2)), MARGIN=1, FUN=mean)
```

When controlling FDR, the FDP was 0.08793 and TDR 0.00251. For the Bonferroni correction of FWE, the FDP was 0.07617 and the TDR was 0.00181. Both manners of adjusting the p-values had similar powers in this case.
<\br>
<\br>


```{r, echo=FALSE, cache=TRUE}
set.seed(4771)
means = seq(.01,1,by=.01)
TrueFalse.2c = apply(replicate(B, do.one(meandiff=means)), MARGIN=1, FUN=mean)
```

When the differentially expressed genes followed N(0.01,1), ..., N(1.00,1) distributions, controlling the FDR at .10 yielded an estimated false discovery proportion of 0.08933 and true discovery rate of 0.4309. Controlling the FWE instead yielded FDP of 0.003688 and TDR of 0.2146. In this scenario, the TDR obtained by controlling FDR is about twice the power obtained by controlling the FWE.

### Problem 3

```{r}
person.t = function(genes=1000){
  c(rt(n=genes,df=3))
  }

experiment.t = function(N){
  class1 = replicate(N, person.t())
  class2 = replicate(N, person.t())
  return(cbind(class1,class2))
  }

do.one.t = function(N=10,meandiff=0,fdr=0.10){
  XP = experiment.t(N=N)
  class = 1:N
  p.values = apply(XP,MARGIN=1,FUN=function(X){t.test(X[class],X[-class])$p.val})
  BH.vals = p.adjust(p.values,method="BH")
  bon.vals = p.adjust(p.values,method="bonferroni")

  BH.n.discoveries = sum(BH.vals < fdr)

  bon.n.discoveries = sum(bon.vals < fdr)
  
  return(c(BH=BH.n.discoveries,Bonf=bon.n.discoveries))
}

TrueFalse.3 = apply(replicate(B, do.one.t()), MARGIN=1, FUN=mean)

```
The proportion discoveries was 0.026 when controlling FDR at .10 and 0.025 when controlling the FWE at .10.

```{r}
do.one.z = function(N=10,meandiff=0,fdr=0.10){
  XP = experiment.t(N=N)
  class = 1:N
  p.values = apply(XP,MARGIN=1,FUN=function(X){pnorm(mean(X[class])-mean(X[-class]), mean=0, sd=sqrt(N*3))})
  BH.vals = p.adjust(p.values,method="BH")
  bon.vals = p.adjust(p.values,method="bonferroni")

  BH.n.discoveries = sum(BH.vals < fdr)

  bon.n.discoveries = sum(bon.vals < fdr)
  
  return(c(BH=BH.n.discoveries,Bonf=bon.n.discoveries))
}

TrueFalse.4 = apply(replicate(B, do.one.t()), MARGIN=1, FUN=mean)

```

The proportion of discoveries was 0.021 for both methods.
